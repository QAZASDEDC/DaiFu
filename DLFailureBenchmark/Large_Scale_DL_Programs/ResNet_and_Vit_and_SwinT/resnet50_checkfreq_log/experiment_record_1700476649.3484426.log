2023-11-20 14:47:58.161 | INFO     | daifu:<module>:34 - Program Begin
2023-11-20 14:48:13.060 | INFO     | torch._tensor:to:88 - Fault Injected To: (0, 0)
2023-11-20 14:48:31.961 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (0, 0) Fault Recovered
2023-11-20 14:48:46.147 | INFO     | torch._tensor:to:88 - Fault Injected To: (50, 0)
2023-11-20 14:49:19.236 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (50, 0) Fault Recovered
2023-11-20 14:49:36.010 | INFO     | torch._tensor:to:88 - Fault Injected To: (100, 0)
2023-11-20 14:50:31.185 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (100, 0) Fault Recovered
2023-11-20 14:50:50.949 | INFO     | torch._tensor:to:88 - Fault Injected To: (150, 0)
2023-11-20 14:51:01.952 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 14:51:01.953 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 14:51:09.781 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (150, 0) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 14:51:29.006 | INFO     | torch._tensor:to:88 - Fault Injected To: (200, 0)
2023-11-20 14:51:49.141 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (200, 0) Fault Recovered
2023-11-20 14:52:09.407 | INFO     | torch._tensor:to:88 - Fault Injected To: (250, 0)
2023-11-20 14:52:27.844 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (250, 0) Fault Recovered
2023-11-20 14:52:47.485 | INFO     | torch._tensor:to:88 - Fault Injected To: (300, 0)
2023-11-20 14:53:06.964 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (300, 0) Fault Recovered
2023-11-20 14:53:26.114 | INFO     | torch._tensor:to:88 - Fault Injected To: (350, 0)
2023-11-20 14:53:45.557 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (350, 0) Fault Recovered
2023-11-20 14:54:05.717 | INFO     | torch._tensor:to:88 - Fault Injected To: (400, 0)
2023-11-20 14:54:25.348 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (400, 0) Fault Recovered
2023-11-20 14:54:44.947 | INFO     | torch._tensor:to:88 - Fault Injected To: (450, 0)
2023-11-20 14:54:54.865 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 14:54:54.865 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 14:55:02.805 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (450, 0) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 14:55:22.552 | INFO     | torch._tensor:to:88 - Fault Injected To: (500, 0)
2023-11-20 14:55:42.229 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (500, 0) Fault Recovered
2023-11-20 14:56:01.448 | INFO     | torch._tensor:to:88 - Fault Injected To: (550, 0)
2023-11-20 14:56:12.296 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 14:56:12.297 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 14:56:20.260 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (550, 0) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 14:56:39.431 | INFO     | torch._tensor:to:88 - Fault Injected To: (600, 0)
2023-11-20 14:56:59.101 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (600, 0) Fault Recovered
2023-11-20 14:57:19.098 | INFO     | torch._tensor:to:88 - Fault Injected To: (650, 0)
2023-11-20 14:57:29.995 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 14:57:29.997 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 14:57:37.968 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (650, 0) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 14:57:57.218 | INFO     | torch._tensor:to:88 - Fault Injected To: (700, 0)
2023-11-20 14:58:16.920 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (700, 0) Fault Recovered
2023-11-20 14:58:36.847 | INFO     | torch._tensor:to:88 - Fault Injected To: (750, 0)
2023-11-20 14:58:56.416 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (750, 0) Fault Recovered
2023-11-20 14:59:16.067 | INFO     | torch._tensor:to:88 - Fault Injected To: (800, 0)
2023-11-20 14:59:35.348 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (800, 0) Fault Recovered
2023-11-20 14:59:54.505 | INFO     | torch._tensor:to:88 - Fault Injected To: (850, 0)
2023-11-20 15:00:13.203 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (850, 0) Fault Recovered
2023-11-20 15:00:32.803 | INFO     | torch._tensor:to:88 - Fault Injected To: (900, 0)
2023-11-20 15:00:52.448 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (900, 0) Fault Recovered
2023-11-20 15:01:12.300 | INFO     | torch._tensor:to:88 - Fault Injected To: (950, 0)
2023-11-20 15:01:23.142 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 15:01:23.143 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 15:01:31.000 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (950, 0) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 15:01:50.206 | INFO     | torch._tensor:to:88 - Fault Injected To: (1000, 0)
2023-11-20 15:02:01.161 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 15:02:01.162 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 15:02:09.054 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1000, 0) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 15:02:28.126 | INFO     | torch._tensor:to:88 - Fault Injected To: (1050, 0)
2023-11-20 15:02:47.363 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1050, 0) Fault Recovered
2023-11-20 15:03:07.171 | INFO     | torch._tensor:to:88 - Fault Injected To: (1100, 0)
2023-11-20 15:03:26.512 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1100, 0) Fault Recovered
2023-11-20 15:03:43.438 | INFO     | torch._tensor:to:88 - Fault Injected To: (1150, 0)
2023-11-20 15:04:17.172 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1150, 0) Fault Recovered
2023-11-20 15:04:32.555 | INFO     | torch._tensor:to:88 - Fault Injected To: (1200, 0)
2023-11-20 15:05:21.197 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1200, 0) Fault Recovered
2023-11-20 15:05:37.406 | INFO     | torch._tensor:to:88 - Fault Injected To: (1250, 0)
2023-11-20 15:05:56.496 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1250, 0) Fault Recovered
2023-11-20 15:06:12.219 | INFO     | torch._tensor:to:88 - Fault Injected To: (1300, 0)
2023-11-20 15:06:45.987 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1300, 0) Fault Recovered
2023-11-20 15:07:01.456 | INFO     | torch._tensor:to:88 - Fault Injected To: (1350, 0)
2023-11-20 15:07:49.374 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1350, 0) Fault Recovered
2023-11-20 15:08:04.800 | INFO     | torch._tensor:to:88 - Fault Injected To: (1400, 0)
2023-11-20 15:08:29.120 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1400, 0) Fault Recovered
2023-11-20 15:08:44.888 | INFO     | torch._tensor:to:88 - Fault Injected To: (1450, 0)
2023-11-20 15:09:23.479 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1450, 0) Fault Recovered
2023-11-20 15:09:38.808 | INFO     | torch._tensor:to:88 - Fault Injected To: (1500, 0)
2023-11-20 15:10:31.519 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1500, 0) Fault Recovered
2023-11-20 15:10:47.068 | INFO     | torch._tensor:to:88 - Fault Injected To: (1550, 0)
2023-11-20 15:11:07.817 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1550, 0) Fault Recovered
2023-11-20 15:11:23.381 | INFO     | torch._tensor:to:88 - Fault Injected To: (1600, 0)
2023-11-20 15:11:58.766 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1600, 0) Fault Recovered
2023-11-20 15:12:14.141 | INFO     | torch._tensor:to:88 - Fault Injected To: (1650, 0)
2023-11-20 15:13:04.731 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1650, 0) Fault Recovered
2023-11-20 15:13:20.149 | INFO     | torch._tensor:to:88 - Fault Injected To: (1700, 0)
2023-11-20 15:13:40.854 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1700, 0) Fault Recovered
2023-11-20 15:13:56.565 | INFO     | torch._tensor:to:88 - Fault Injected To: (1750, 0)
2023-11-20 15:14:32.175 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1750, 0) Fault Recovered
2023-11-20 15:14:47.413 | INFO     | torch._tensor:to:88 - Fault Injected To: (1800, 0)
2023-11-20 15:15:37.440 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1800, 0) Fault Recovered
2023-11-20 15:15:53.253 | INFO     | torch._tensor:to:88 - Fault Injected To: (1850, 0)
2023-11-20 15:16:18.560 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1850, 0) Fault Recovered
2023-11-20 15:16:34.106 | INFO     | torch._tensor:to:88 - Fault Injected To: (1900, 0)
2023-11-20 15:17:14.131 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1900, 0) Fault Recovered
2023-11-20 15:17:29.755 | INFO     | torch._tensor:to:88 - Fault Injected To: (1950, 0)
2023-11-20 15:18:24.659 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1950, 0) Fault Recovered
2023-11-20 15:18:39.837 | INFO     | torch._tensor:to:88 - Fault Injected To: (2000, 0)
2023-11-20 15:19:06.666 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2000, 0) Fault Recovered
2023-11-20 15:19:22.515 | INFO     | torch._tensor:to:88 - Fault Injected To: (2050, 0)
2023-11-20 15:20:04.195 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2050, 0) Fault Recovered
2023-11-20 15:20:19.575 | INFO     | torch._tensor:to:88 - Fault Injected To: (2100, 0)
2023-11-20 15:21:15.858 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2100, 0) Fault Recovered
2023-11-20 15:21:30.854 | INFO     | torch._tensor:to:88 - Fault Injected To: (2150, 0)
2023-11-20 15:21:56.305 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2150, 0) Fault Recovered
2023-11-20 15:22:11.850 | INFO     | torch._tensor:to:88 - Fault Injected To: (2200, 0)
2023-11-20 15:22:52.117 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2200, 0) Fault Recovered
2023-11-20 15:23:07.416 | INFO     | torch._tensor:to:88 - Fault Injected To: (2250, 0)
2023-11-20 15:24:01.611 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2250, 0) Fault Recovered
2023-11-20 15:24:17.766 | INFO     | torch._tensor:to:88 - Fault Injected To: (2300, 0)
2023-11-20 15:24:38.708 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2300, 0) Fault Recovered
2023-11-20 15:24:54.339 | INFO     | torch._tensor:to:88 - Fault Injected To: (2350, 0)
2023-11-20 15:25:29.885 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2350, 0) Fault Recovered
2023-11-20 15:25:45.288 | INFO     | torch._tensor:to:88 - Fault Injected To: (2400, 0)
2023-11-20 15:26:35.065 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2400, 0) Fault Recovered
2023-11-20 15:26:50.335 | INFO     | torch._tensor:to:88 - Fault Injected To: (2450, 0)
2023-11-20 15:27:16.747 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2450, 0) Fault Recovered
2023-11-20 15:27:32.625 | INFO     | torch._tensor:to:88 - Fault Injected To: (2500, 0)
2023-11-20 15:28:14.233 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2500, 0) Fault Recovered
2023-11-20 15:28:29.420 | INFO     | torch._tensor:to:88 - Fault Injected To: (2550, 0)
2023-11-20 15:29:24.974 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2550, 0) Fault Recovered
2023-11-20 15:29:40.447 | INFO     | torch._tensor:to:88 - Fault Injected To: (2600, 0)
2023-11-20 15:29:59.947 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2600, 0) Fault Recovered
2023-11-20 15:30:15.177 | INFO     | torch._tensor:to:88 - Fault Injected To: (2650, 0)
2023-11-20 15:30:48.477 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2650, 0) Fault Recovered
2023-11-20 15:31:03.906 | INFO     | torch._tensor:to:88 - Fault Injected To: (2700, 0)
2023-11-20 15:31:52.115 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2700, 0) Fault Recovered
2023-11-20 15:32:07.813 | INFO     | torch._tensor:to:88 - Fault Injected To: (2750, 0)
2023-11-20 15:33:10.180 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2750, 0) Fault Recovered
2023-11-20 15:33:25.924 | INFO     | torch._tensor:to:88 - Fault Injected To: (2800, 0)
2023-11-20 15:33:52.439 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2800, 0) Fault Recovered
2023-11-20 15:34:08.451 | INFO     | torch._tensor:to:88 - Fault Injected To: (2850, 0)
2023-11-20 15:34:49.255 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2850, 0) Fault Recovered
2023-11-20 15:35:05.548 | INFO     | torch._tensor:to:88 - Fault Injected To: (2900, 0)
2023-11-20 15:36:01.167 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2900, 0) Fault Recovered
2023-11-20 15:36:16.668 | INFO     | torch._tensor:to:88 - Fault Injected To: (2950, 0)
2023-11-20 15:36:43.642 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2950, 0) Fault Recovered
2023-11-20 15:36:59.253 | INFO     | torch._tensor:to:88 - Fault Injected To: (3000, 0)
2023-11-20 15:37:39.600 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3000, 0) Fault Recovered
2023-11-20 15:37:55.319 | INFO     | torch._tensor:to:88 - Fault Injected To: (3050, 0)
2023-11-20 15:38:51.097 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3050, 0) Fault Recovered
2023-11-20 15:39:06.596 | INFO     | torch._tensor:to:88 - Fault Injected To: (3100, 0)
2023-11-20 15:39:31.599 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3100, 0) Fault Recovered
2023-11-20 15:39:47.447 | INFO     | torch._tensor:to:88 - Fault Injected To: (3150, 0)
2023-11-20 15:40:26.620 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3150, 0) Fault Recovered
2023-11-20 15:40:42.616 | INFO     | torch._tensor:to:88 - Fault Injected To: (3200, 0)
2023-11-20 15:41:36.632 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3200, 0) Fault Recovered
2023-11-20 15:41:52.384 | INFO     | torch._tensor:to:88 - Fault Injected To: (3250, 0)
2023-11-20 15:42:16.150 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3250, 0) Fault Recovered
2023-11-20 15:42:31.918 | INFO     | torch._tensor:to:88 - Fault Injected To: (3300, 0)
2023-11-20 15:43:09.551 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3300, 0) Fault Recovered
2023-11-20 15:43:25.076 | INFO     | torch._tensor:to:88 - Fault Injected To: (3350, 0)
2023-11-20 15:44:17.257 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3350, 0) Fault Recovered
2023-11-20 15:44:33.012 | INFO     | torch._tensor:to:88 - Fault Injected To: (3400, 0)
2023-11-20 15:45:28.804 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3400, 0) Fault Recovered
2023-11-20 15:45:44.682 | INFO     | torch._tensor:to:88 - Fault Injected To: (3450, 0)
2023-11-20 15:46:09.854 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3450, 0) Fault Recovered
2023-11-20 15:46:25.633 | INFO     | torch._tensor:to:88 - Fault Injected To: (3500, 0)
2023-11-20 15:47:05.567 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3500, 0) Fault Recovered
2023-11-20 15:47:21.237 | INFO     | torch._tensor:to:88 - Fault Injected To: (3550, 0)
2023-11-20 15:48:15.656 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3550, 0) Fault Recovered
2023-11-20 15:48:31.532 | INFO     | torch._tensor:to:88 - Fault Injected To: (3600, 0)
2023-11-20 15:49:28.295 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3600, 0) Fault Recovered
2023-11-20 15:49:43.714 | INFO     | torch._tensor:to:88 - Fault Injected To: (3650, 0)
2023-11-20 15:50:09.824 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3650, 0) Fault Recovered
2023-11-20 15:50:25.822 | INFO     | torch._tensor:to:88 - Fault Injected To: (3700, 0)
2023-11-20 15:51:06.275 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3700, 0) Fault Recovered
2023-11-20 15:51:22.506 | INFO     | torch._tensor:to:88 - Fault Injected To: (3750, 0)
2023-11-20 15:51:43.513 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3750, 0) Fault Recovered
2023-11-20 15:51:59.195 | INFO     | torch._tensor:to:88 - Fault Injected To: (3800, 0)
2023-11-20 15:52:34.777 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3800, 0) Fault Recovered
2023-11-20 15:52:50.688 | INFO     | torch._tensor:to:88 - Fault Injected To: (3850, 0)
2023-11-20 15:53:40.435 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3850, 0) Fault Recovered
2023-11-20 15:53:56.074 | INFO     | torch._tensor:to:88 - Fault Injected To: (3900, 0)
2023-11-20 15:54:15.744 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3900, 0) Fault Recovered
2023-11-20 15:54:31.457 | INFO     | torch._tensor:to:88 - Fault Injected To: (3950, 0)
2023-11-20 15:55:05.199 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (3950, 0) Fault Recovered
2023-11-20 15:55:21.248 | INFO     | torch._tensor:to:88 - Fault Injected To: (4000, 0)
2023-11-20 15:56:08.382 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4000, 0) Fault Recovered
2023-11-20 15:56:23.964 | INFO     | torch._tensor:to:88 - Fault Injected To: (4050, 0)
2023-11-20 15:56:51.202 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4050, 0) Fault Recovered
2023-11-20 15:57:07.678 | INFO     | torch._tensor:to:88 - Fault Injected To: (4100, 0)
2023-11-20 15:57:49.971 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4100, 0) Fault Recovered
2023-11-20 15:58:05.866 | INFO     | torch._tensor:to:88 - Fault Injected To: (4150, 0)
2023-11-20 15:58:38.614 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4150, 0) Fault Recovered
2023-11-20 15:58:54.659 | INFO     | torch._tensor:to:88 - Fault Injected To: (4200, 0)
2023-11-20 15:59:30.166 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4200, 0) Fault Recovered
2023-11-20 15:59:46.149 | INFO     | torch._tensor:to:88 - Fault Injected To: (4250, 0)
2023-11-20 16:00:09.701 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4250, 0) Fault Recovered
2023-11-20 16:00:25.375 | INFO     | torch._tensor:to:88 - Fault Injected To: (4300, 0)
2023-11-20 16:01:04.748 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4300, 0) Fault Recovered
2023-11-20 16:01:20.667 | INFO     | torch._tensor:to:88 - Fault Injected To: (4350, 0)
2023-11-20 16:01:48.262 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4350, 0) Fault Recovered
2023-11-20 16:02:03.836 | INFO     | torch._tensor:to:88 - Fault Injected To: (4400, 0)
2023-11-20 16:02:46.009 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4400, 0) Fault Recovered
2023-11-20 16:03:01.593 | INFO     | torch._tensor:to:88 - Fault Injected To: (4450, 0)
2023-11-20 16:03:30.926 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4450, 0) Fault Recovered
2023-11-20 16:03:46.745 | INFO     | torch._tensor:to:88 - Fault Injected To: (4500, 0)
2023-11-20 16:04:30.961 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4500, 0) Fault Recovered
2023-11-20 16:04:47.408 | INFO     | torch._tensor:to:88 - Fault Injected To: (4550, 0)
2023-11-20 16:05:19.703 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4550, 0) Fault Recovered
2023-11-20 16:05:35.879 | INFO     | torch._tensor:to:88 - Fault Injected To: (4600, 0)
2023-11-20 16:06:22.743 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4600, 0) Fault Recovered
2023-11-20 16:06:38.569 | INFO     | torch._tensor:to:88 - Fault Injected To: (4650, 0)
2023-11-20 16:06:57.972 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4650, 0) Fault Recovered
2023-11-20 16:07:13.459 | INFO     | torch._tensor:to:88 - Fault Injected To: (4700, 0)
2023-11-20 16:07:46.836 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4700, 0) Fault Recovered
2023-11-20 16:08:02.591 | INFO     | torch._tensor:to:88 - Fault Injected To: (4750, 0)
2023-11-20 16:08:50.459 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4750, 0) Fault Recovered
2023-11-20 16:09:05.963 | INFO     | torch._tensor:to:88 - Fault Injected To: (4800, 0)
2023-11-20 16:09:54.129 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4800, 0) Fault Recovered
2023-11-20 16:10:09.773 | INFO     | torch._tensor:to:88 - Fault Injected To: (4850, 0)
2023-11-20 16:10:30.073 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4850, 0) Fault Recovered
2023-11-20 16:10:46.188 | INFO     | torch._tensor:to:88 - Fault Injected To: (4900, 0)
2023-11-20 16:11:21.413 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4900, 0) Fault Recovered
2023-11-20 16:11:36.945 | INFO     | torch._tensor:to:88 - Fault Injected To: (4950, 0)
2023-11-20 16:12:26.026 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (4950, 0) Fault Recovered
2023-11-20 16:12:41.522 | INFO     | torch._tensor:to:88 - Fault Injected To: (5000, 0)
2023-11-20 16:13:01.109 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (5000, 0) Fault Recovered
2023-11-20 16:14:18.605 | INFO     | torch:fault_injection_scheduler_and_recorder_for_epoch:1033 - 0 Fault Recovered
2023-11-20 16:14:20.981 | INFO     | torch._tensor:to:88 - Fault Injected To: (0, 1)
2023-11-20 16:14:42.041 | INFO     | torch.serialization:save:378 - Fault Injected To: 0
2023-11-20 16:15:49.814 | INFO     | torch.distributed.distributed_c10d:all_reduce:1308 - Fault Injected To: 0
2023-11-20 16:17:21.226 | INFO     | torch:fault_injection_scheduler_and_recorder_for_epoch:1033 - 0 Fault Recovered
2023-11-20 16:17:23.737 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (0, 1) Fault Recovered
2023-11-20 16:17:38.445 | INFO     | torch._tensor:to:88 - Fault Injected To: (50, 1)
2023-11-20 16:17:59.465 | INFO     | torch.serialization:save:378 - Fault Injected To: 0
2023-11-20 16:19:07.904 | INFO     | torch.distributed.distributed_c10d:all_reduce:1308 - Fault Injected To: 0
2023-11-20 16:20:39.400 | INFO     | torch:fault_injection_scheduler_and_recorder_for_epoch:1033 - 0 Fault Recovered
2023-11-20 16:20:56.476 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (50, 1) Fault Recovered
2023-11-20 16:21:11.234 | INFO     | torch._tensor:to:88 - Fault Injected To: (100, 1)
2023-11-20 16:21:31.204 | INFO     | torch.serialization:save:378 - Fault Injected To: 0
2023-11-20 16:22:40.094 | INFO     | torch.distributed.distributed_c10d:all_reduce:1308 - Fault Injected To: 0
2023-11-20 16:24:11.070 | INFO     | torch:fault_injection_scheduler_and_recorder_for_epoch:1033 - 0 Fault Recovered
2023-11-20 16:24:42.534 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (100, 1) Fault Recovered
2023-11-20 16:24:56.931 | INFO     | torch._tensor:to:88 - Fault Injected To: (150, 1)
2023-11-20 16:25:59.000 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (150, 1) Fault Recovered
2023-11-20 16:26:13.940 | INFO     | torch._tensor:to:88 - Fault Injected To: (200, 1)
2023-11-20 16:26:46.296 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (200, 1) Fault Recovered
2023-11-20 16:27:01.101 | INFO     | torch._tensor:to:88 - Fault Injected To: (250, 1)
2023-11-20 16:27:47.923 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (250, 1) Fault Recovered
2023-11-20 16:28:03.068 | INFO     | torch._tensor:to:88 - Fault Injected To: (300, 1)
2023-11-20 16:29:04.541 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (300, 1) Fault Recovered
2023-11-20 16:29:19.292 | INFO     | torch._tensor:to:88 - Fault Injected To: (350, 1)
2023-11-20 16:30:20.703 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (350, 1) Fault Recovered
2023-11-20 16:30:35.655 | INFO     | torch._tensor:to:88 - Fault Injected To: (400, 1)
2023-11-20 16:31:07.203 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (400, 1) Fault Recovered
2023-11-20 16:31:22.216 | INFO     | torch._tensor:to:88 - Fault Injected To: (450, 1)
2023-11-20 16:32:08.041 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (450, 1) Fault Recovered
2023-11-20 16:32:23.061 | INFO     | torch._tensor:to:88 - Fault Injected To: (500, 1)
2023-11-20 16:33:23.470 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (500, 1) Fault Recovered
2023-11-20 16:33:38.239 | INFO     | torch._tensor:to:88 - Fault Injected To: (550, 1)
2023-11-20 16:34:38.543 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (550, 1) Fault Recovered
2023-11-20 16:34:53.323 | INFO     | torch._tensor:to:88 - Fault Injected To: (600, 1)
2023-11-20 16:35:23.380 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (600, 1) Fault Recovered
2023-11-20 16:35:38.349 | INFO     | torch._tensor:to:88 - Fault Injected To: (650, 1)
2023-11-20 16:36:23.094 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (650, 1) Fault Recovered
2023-11-20 16:36:37.976 | INFO     | torch._tensor:to:88 - Fault Injected To: (700, 1)
2023-11-20 16:37:37.208 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (700, 1) Fault Recovered
2023-11-20 16:37:52.222 | INFO     | torch._tensor:to:88 - Fault Injected To: (750, 1)
2023-11-20 16:38:51.429 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (750, 1) Fault Recovered
2023-11-20 16:39:06.081 | INFO     | torch._tensor:to:88 - Fault Injected To: (800, 1)
2023-11-20 16:39:35.230 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (800, 1) Fault Recovered
2023-11-20 16:39:50.179 | INFO     | torch._tensor:to:88 - Fault Injected To: (850, 1)
2023-11-20 16:40:33.807 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (850, 1) Fault Recovered
2023-11-20 16:40:48.566 | INFO     | torch._tensor:to:88 - Fault Injected To: (900, 1)
2023-11-20 16:41:46.508 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (900, 1) Fault Recovered
2023-11-20 16:42:01.261 | INFO     | torch._tensor:to:88 - Fault Injected To: (950, 1)
2023-11-20 16:42:59.507 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (950, 1) Fault Recovered
2023-11-20 16:43:14.449 | INFO     | torch._tensor:to:88 - Fault Injected To: (1000, 1)
2023-11-20 16:43:42.428 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1000, 1) Fault Recovered
2023-11-20 16:43:57.695 | INFO     | torch._tensor:to:88 - Fault Injected To: (1050, 1)
2023-11-20 16:44:40.388 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1050, 1) Fault Recovered
2023-11-20 16:44:55.724 | INFO     | torch._tensor:to:88 - Fault Injected To: (1100, 1)
2023-11-20 16:45:52.896 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1100, 1) Fault Recovered
2023-11-20 16:46:07.668 | INFO     | torch._tensor:to:88 - Fault Injected To: (1150, 1)
2023-11-20 16:47:05.246 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1150, 1) Fault Recovered
2023-11-20 16:47:20.342 | INFO     | torch._tensor:to:88 - Fault Injected To: (1200, 1)
2023-11-20 16:47:46.373 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1200, 1) Fault Recovered
2023-11-20 16:48:01.385 | INFO     | torch._tensor:to:88 - Fault Injected To: (1250, 1)
2023-11-20 16:48:41.266 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1250, 1) Fault Recovered
2023-11-20 16:48:56.349 | INFO     | torch._tensor:to:88 - Fault Injected To: (1300, 1)
2023-11-20 16:49:51.263 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1300, 1) Fault Recovered
2023-11-20 16:50:06.446 | INFO     | torch._tensor:to:88 - Fault Injected To: (1350, 1)
2023-11-20 16:51:00.544 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1350, 1) Fault Recovered
2023-11-20 16:51:15.813 | INFO     | torch._tensor:to:88 - Fault Injected To: (1400, 1)
2023-11-20 16:51:38.735 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1400, 1) Fault Recovered
2023-11-20 16:51:53.649 | INFO     | torch._tensor:to:88 - Fault Injected To: (1450, 1)
2023-11-20 16:52:30.773 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1450, 1) Fault Recovered
2023-11-20 16:52:46.211 | INFO     | torch._tensor:to:88 - Fault Injected To: (1500, 1)
2023-11-20 16:53:38.407 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1500, 1) Fault Recovered
2023-11-20 16:53:53.185 | INFO     | torch._tensor:to:88 - Fault Injected To: (1550, 1)
2023-11-20 16:54:59.186 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1550, 1) Fault Recovered
2023-11-20 16:55:13.968 | INFO     | torch._tensor:to:88 - Fault Injected To: (1600, 1)
2023-11-20 16:56:02.432 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1600, 1) Fault Recovered
2023-11-20 16:56:18.022 | INFO     | torch._tensor:to:88 - Fault Injected To: (1650, 1)
2023-11-20 16:57:05.737 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1650, 1) Fault Recovered
2023-11-20 16:57:20.739 | INFO     | torch._tensor:to:88 - Fault Injected To: (1700, 1)
2023-11-20 16:57:50.190 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1700, 1) Fault Recovered
2023-11-20 16:58:04.977 | INFO     | torch._tensor:to:88 - Fault Injected To: (1750, 1)
2023-11-20 16:58:49.334 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1750, 1) Fault Recovered
2023-11-20 16:59:04.284 | INFO     | torch._tensor:to:88 - Fault Injected To: (1800, 1)
2023-11-20 16:59:31.501 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1800, 1) Fault Recovered
2023-11-20 16:59:46.866 | INFO     | torch._tensor:to:88 - Fault Injected To: (1850, 1)
2023-11-20 17:00:27.721 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1850, 1) Fault Recovered
2023-11-20 17:00:43.101 | INFO     | torch._tensor:to:88 - Fault Injected To: (1900, 1)
2023-11-20 17:01:06.940 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1900, 1) Fault Recovered
2023-11-20 17:01:22.194 | INFO     | torch._tensor:to:88 - Fault Injected To: (1950, 1)
2023-11-20 17:02:00.713 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (1950, 1) Fault Recovered
2023-11-20 17:02:16.528 | INFO     | torch._tensor:to:88 - Fault Injected To: (2000, 1)
2023-11-20 17:02:36.388 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2000, 1) Fault Recovered
2023-11-20 17:02:51.302 | INFO     | torch._tensor:to:88 - Fault Injected To: (2050, 1)
2023-11-20 17:03:26.157 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2050, 1) Fault Recovered
2023-11-20 17:03:41.139 | INFO     | torch._tensor:to:88 - Fault Injected To: (2100, 1)
2023-11-20 17:04:29.995 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2100, 1) Fault Recovered
2023-11-20 17:04:45.207 | INFO     | torch._tensor:to:88 - Fault Injected To: (2150, 1)
2023-11-20 17:05:14.718 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2150, 1) Fault Recovered
2023-11-20 17:05:29.850 | INFO     | torch._tensor:to:88 - Fault Injected To: (2200, 1)
2023-11-20 17:06:12.733 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2200, 1) Fault Recovered
2023-11-20 17:06:27.834 | INFO     | torch._tensor:to:88 - Fault Injected To: (2250, 1)
2023-11-20 17:06:51.905 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2250, 1) Fault Recovered
2023-11-20 17:07:06.982 | INFO     | torch._tensor:to:88 - Fault Injected To: (2300, 1)
2023-11-20 17:07:45.625 | INFO     | torch:fault_injection_scheduler_and_recorder:997 - (2300, 1) Fault Recovered
2023-11-20 17:08:00.830 | INFO     | torch._tensor:to:88 - Fault Injected To: (2350, 1)
2023-11-20 17:08:10.926 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:08:10.926 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:08:19.144 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2350, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:08:33.992 | INFO     | torch._tensor:to:88 - Fault Injected To: (2400, 1)
2023-11-20 17:08:44.752 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:08:44.752 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:08:52.734 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2400, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:09:07.368 | INFO     | torch._tensor:to:88 - Fault Injected To: (2450, 1)
2023-11-20 17:09:18.164 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:09:18.165 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:09:26.023 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2450, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:09:41.125 | INFO     | torch._tensor:to:88 - Fault Injected To: (2500, 1)
2023-11-20 17:09:52.031 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:09:52.032 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:10:00.008 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2500, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:10:15.283 | INFO     | torch._tensor:to:88 - Fault Injected To: (2550, 1)
2023-11-20 17:10:26.199 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:10:26.199 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:10:34.367 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2550, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:10:49.185 | INFO     | torch._tensor:to:88 - Fault Injected To: (2600, 1)
2023-11-20 17:11:00.073 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:11:00.074 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:11:08.006 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2600, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:11:22.728 | INFO     | torch._tensor:to:88 - Fault Injected To: (2650, 1)
2023-11-20 17:11:33.616 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:11:33.617 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:11:41.483 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2650, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:11:56.067 | INFO     | torch._tensor:to:88 - Fault Injected To: (2700, 1)
2023-11-20 17:12:06.814 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:12:06.815 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:12:14.870 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2700, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:12:29.705 | INFO     | torch._tensor:to:88 - Fault Injected To: (2750, 1)
2023-11-20 17:12:40.654 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:12:40.655 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:12:48.691 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2750, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:13:03.370 | INFO     | torch._tensor:to:88 - Fault Injected To: (2800, 1)
2023-11-20 17:13:14.280 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:13:14.281 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:13:22.597 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2800, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:13:37.602 | INFO     | torch._tensor:to:88 - Fault Injected To: (2850, 1)
2023-11-20 17:13:48.491 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:13:48.492 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:13:56.422 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2850, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:14:11.098 | INFO     | torch._tensor:to:88 - Fault Injected To: (2900, 1)
2023-11-20 17:14:21.962 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:14:21.963 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:14:30.032 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2900, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:14:44.820 | INFO     | torch._tensor:to:88 - Fault Injected To: (2950, 1)
2023-11-20 17:14:55.646 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:14:55.648 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:15:03.645 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2950, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:15:19.087 | INFO     | torch._tensor:to:88 - Fault Injected To: (3000, 1)
2023-11-20 17:15:29.838 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:15:29.839 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:15:37.932 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3000, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:15:52.835 | INFO     | torch._tensor:to:88 - Fault Injected To: (3050, 1)
2023-11-20 17:16:03.776 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:16:03.778 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:16:11.934 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3050, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:16:27.125 | INFO     | torch._tensor:to:88 - Fault Injected To: (3100, 1)
2023-11-20 17:16:37.996 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:16:37.997 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:16:45.952 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3100, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:17:00.396 | INFO     | torch._tensor:to:88 - Fault Injected To: (3150, 1)
2023-11-20 17:17:11.276 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:17:11.277 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:17:19.436 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3150, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:17:34.293 | INFO     | torch._tensor:to:88 - Fault Injected To: (3200, 1)
2023-11-20 17:17:44.244 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:17:44.245 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:17:52.358 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3200, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:18:07.466 | INFO     | torch._tensor:to:88 - Fault Injected To: (3250, 1)
2023-11-20 17:18:17.476 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:18:17.477 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:18:25.481 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3250, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:18:40.537 | INFO     | torch._tensor:to:88 - Fault Injected To: (3300, 1)
2023-11-20 17:18:51.411 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:18:51.412 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:18:59.376 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3300, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:19:14.534 | INFO     | torch._tensor:to:88 - Fault Injected To: (3350, 1)
2023-11-20 17:19:25.407 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:19:25.407 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:19:33.331 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3350, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:19:48.158 | INFO     | torch._tensor:to:88 - Fault Injected To: (3400, 1)
2023-11-20 17:19:58.983 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:19:58.984 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:20:06.998 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3400, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:20:21.834 | INFO     | torch._tensor:to:88 - Fault Injected To: (3450, 1)
2023-11-20 17:20:32.703 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:20:32.704 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:20:40.686 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3450, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:20:55.786 | INFO     | torch._tensor:to:88 - Fault Injected To: (3500, 1)
2023-11-20 17:21:05.699 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:21:05.700 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:21:13.775 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3500, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:21:28.653 | INFO     | torch._tensor:to:88 - Fault Injected To: (3550, 1)
2023-11-20 17:21:39.553 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:21:39.554 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:21:47.539 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3550, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:22:02.561 | INFO     | torch._tensor:to:88 - Fault Injected To: (3600, 1)
2023-11-20 17:22:13.520 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:22:13.521 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:22:21.800 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3600, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:22:36.699 | INFO     | torch._tensor:to:88 - Fault Injected To: (3650, 1)
2023-11-20 17:22:46.661 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:22:46.662 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:22:54.990 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3650, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:23:10.662 | INFO     | torch._tensor:to:88 - Fault Injected To: (3700, 1)
2023-11-20 17:23:21.756 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:23:21.757 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:23:29.801 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3700, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:23:44.807 | INFO     | torch._tensor:to:88 - Fault Injected To: (3750, 1)
2023-11-20 17:23:55.696 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:23:55.697 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:24:03.818 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3750, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:24:18.888 | INFO     | torch._tensor:to:88 - Fault Injected To: (3800, 1)
2023-11-20 17:24:29.807 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:24:29.809 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:24:37.805 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3800, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:24:52.585 | INFO     | torch._tensor:to:88 - Fault Injected To: (3850, 1)
2023-11-20 17:25:03.591 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:25:03.592 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:25:11.565 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3850, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:25:26.720 | INFO     | torch._tensor:to:88 - Fault Injected To: (3900, 1)
2023-11-20 17:25:37.646 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:25:37.648 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:25:45.654 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3900, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:26:00.247 | INFO     | torch._tensor:to:88 - Fault Injected To: (3950, 1)
2023-11-20 17:26:11.096 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:26:11.097 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:26:18.983 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3950, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:26:33.975 | INFO     | torch._tensor:to:88 - Fault Injected To: (4000, 1)
2023-11-20 17:26:44.732 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:26:44.733 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:26:52.822 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4000, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:27:07.968 | INFO     | torch._tensor:to:88 - Fault Injected To: (4050, 1)
2023-11-20 17:27:18.866 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:27:18.868 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:27:26.823 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4050, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:27:41.855 | INFO     | torch._tensor:to:88 - Fault Injected To: (4100, 1)
2023-11-20 17:27:52.652 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:27:52.653 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:28:00.712 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4100, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:28:16.022 | INFO     | torch._tensor:to:88 - Fault Injected To: (4150, 1)
2023-11-20 17:28:26.870 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:28:26.871 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:28:34.855 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4150, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:28:50.003 | INFO     | torch._tensor:to:88 - Fault Injected To: (4200, 1)
2023-11-20 17:29:00.878 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:29:00.879 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:29:08.929 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4200, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:29:24.656 | INFO     | torch._tensor:to:88 - Fault Injected To: (4250, 1)
2023-11-20 17:29:35.568 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:29:35.569 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:29:43.733 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4250, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:29:58.875 | INFO     | torch._tensor:to:88 - Fault Injected To: (4300, 1)
2023-11-20 17:30:09.810 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:30:09.811 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:30:17.813 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4300, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:30:33.471 | INFO     | torch._tensor:to:88 - Fault Injected To: (4350, 1)
2023-11-20 17:30:44.361 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:30:44.362 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:30:52.421 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4350, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:31:07.669 | INFO     | torch._tensor:to:88 - Fault Injected To: (4400, 1)
2023-11-20 17:31:18.535 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:31:18.537 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:31:26.458 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4400, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:31:41.810 | INFO     | torch._tensor:to:88 - Fault Injected To: (4450, 1)
2023-11-20 17:31:52.774 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:31:52.776 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:32:00.737 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4450, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:32:15.915 | INFO     | torch._tensor:to:88 - Fault Injected To: (4500, 1)
2023-11-20 17:32:26.830 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:32:26.831 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:32:35.212 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4500, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:32:50.390 | INFO     | torch._tensor:to:88 - Fault Injected To: (4550, 1)
2023-11-20 17:33:01.280 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:33:01.282 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:33:09.284 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4550, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:33:24.787 | INFO     | torch._tensor:to:88 - Fault Injected To: (4600, 1)
2023-11-20 17:33:35.704 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:33:35.705 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:33:43.627 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4600, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:33:59.131 | INFO     | torch._tensor:to:88 - Fault Injected To: (4650, 1)
2023-11-20 17:34:09.992 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:34:09.993 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:34:17.928 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4650, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:34:32.983 | INFO     | torch._tensor:to:88 - Fault Injected To: (4700, 1)
2023-11-20 17:34:43.903 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:34:43.904 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:34:51.785 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4700, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:35:07.475 | INFO     | torch._tensor:to:88 - Fault Injected To: (4750, 1)
2023-11-20 17:35:18.323 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:35:18.324 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:35:26.522 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4750, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:35:42.038 | INFO     | torch._tensor:to:88 - Fault Injected To: (4800, 1)
2023-11-20 17:35:52.974 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:35:52.975 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:36:00.846 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4800, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:36:15.976 | INFO     | torch._tensor:to:88 - Fault Injected To: (4850, 1)
2023-11-20 17:36:26.762 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:36:26.763 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:36:34.726 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4850, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:36:50.167 | INFO     | torch._tensor:to:88 - Fault Injected To: (4900, 1)
2023-11-20 17:37:01.035 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:37:01.037 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:37:09.280 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4900, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:37:24.691 | INFO     | torch._tensor:to:88 - Fault Injected To: (4950, 1)
2023-11-20 17:37:35.752 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:37:35.752 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:37:43.651 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4950, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:37:58.821 | INFO     | torch._tensor:to:88 - Fault Injected To: (5000, 1)
2023-11-20 17:38:09.699 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:38:09.700 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:38:17.720 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (5000, 1) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:39:33.320 | INFO     | torch:fault_injection_scheduler_and_recorder_for_epoch:1035 - 1 Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:39:37.033 | INFO     | torch._tensor:to:88 - Fault Injected To: (0, 2)
2023-11-20 17:39:46.797 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:39:46.798 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:39:54.819 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (0, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:40:09.366 | INFO     | torch._tensor:to:88 - Fault Injected To: (50, 2)
2023-11-20 17:40:20.208 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:40:20.209 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:40:28.147 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (50, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:40:42.588 | INFO     | torch._tensor:to:88 - Fault Injected To: (100, 2)
2023-11-20 17:40:53.535 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:40:53.536 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:41:01.339 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (100, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:41:15.561 | INFO     | torch._tensor:to:88 - Fault Injected To: (150, 2)
2023-11-20 17:41:26.459 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:41:26.460 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:41:34.741 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (150, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:41:48.974 | INFO     | torch._tensor:to:88 - Fault Injected To: (200, 2)
2023-11-20 17:42:00.046 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:42:00.047 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:42:08.112 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (200, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:42:22.851 | INFO     | torch._tensor:to:88 - Fault Injected To: (250, 2)
2023-11-20 17:42:33.646 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:42:33.647 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:42:41.559 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (250, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:42:56.380 | INFO     | torch._tensor:to:88 - Fault Injected To: (300, 2)
2023-11-20 17:43:07.244 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:43:07.245 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:43:15.118 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (300, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:43:29.480 | INFO     | torch._tensor:to:88 - Fault Injected To: (350, 2)
2023-11-20 17:43:40.312 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:43:40.313 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:43:48.294 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (350, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:44:02.767 | INFO     | torch._tensor:to:88 - Fault Injected To: (400, 2)
2023-11-20 17:44:13.708 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:44:13.709 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:44:21.595 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (400, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:44:35.916 | INFO     | torch._tensor:to:88 - Fault Injected To: (450, 2)
2023-11-20 17:44:46.815 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:44:46.816 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:44:54.869 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (450, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:45:09.358 | INFO     | torch._tensor:to:88 - Fault Injected To: (500, 2)
2023-11-20 17:45:20.217 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:45:20.218 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:45:28.219 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (500, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:45:42.606 | INFO     | torch._tensor:to:88 - Fault Injected To: (550, 2)
2023-11-20 17:45:53.496 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:45:53.497 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:46:01.495 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (550, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:46:15.806 | INFO     | torch._tensor:to:88 - Fault Injected To: (600, 2)
2023-11-20 17:46:26.734 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:46:26.736 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:46:34.846 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (600, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:46:49.324 | INFO     | torch._tensor:to:88 - Fault Injected To: (650, 2)
2023-11-20 17:46:59.334 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:46:59.335 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:47:07.326 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (650, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:47:21.678 | INFO     | torch._tensor:to:88 - Fault Injected To: (700, 2)
2023-11-20 17:47:32.498 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:47:32.498 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:47:40.596 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (700, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:47:55.210 | INFO     | torch._tensor:to:88 - Fault Injected To: (750, 2)
2023-11-20 17:48:04.975 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:48:04.976 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:48:12.923 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (750, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:48:27.594 | INFO     | torch._tensor:to:88 - Fault Injected To: (800, 2)
2023-11-20 17:48:38.361 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:48:38.362 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:48:46.373 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (800, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:49:00.927 | INFO     | torch._tensor:to:88 - Fault Injected To: (850, 2)
2023-11-20 17:49:10.696 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:49:10.697 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:49:18.529 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (850, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:49:32.853 | INFO     | torch._tensor:to:88 - Fault Injected To: (900, 2)
2023-11-20 17:49:43.726 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:49:43.727 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:49:51.515 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (900, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:50:06.212 | INFO     | torch._tensor:to:88 - Fault Injected To: (950, 2)
2023-11-20 17:50:17.065 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:50:17.067 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:50:25.299 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (950, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:50:39.863 | INFO     | torch._tensor:to:88 - Fault Injected To: (1000, 2)
2023-11-20 17:50:50.808 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:50:50.809 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:50:58.939 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1000, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:51:13.164 | INFO     | torch._tensor:to:88 - Fault Injected To: (1050, 2)
2023-11-20 17:51:24.116 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:51:24.117 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:51:32.149 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1050, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:51:46.530 | INFO     | torch._tensor:to:88 - Fault Injected To: (1100, 2)
2023-11-20 17:51:57.418 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:51:57.420 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:52:05.336 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1100, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:52:20.030 | INFO     | torch._tensor:to:88 - Fault Injected To: (1150, 2)
2023-11-20 17:52:30.788 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:52:30.789 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:52:38.780 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1150, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:52:53.542 | INFO     | torch._tensor:to:88 - Fault Injected To: (1200, 2)
2023-11-20 17:53:04.388 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:53:04.389 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:53:12.560 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1200, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:53:27.275 | INFO     | torch._tensor:to:88 - Fault Injected To: (1250, 2)
2023-11-20 17:53:38.158 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:53:38.159 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:53:46.225 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1250, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:54:00.641 | INFO     | torch._tensor:to:88 - Fault Injected To: (1300, 2)
2023-11-20 17:54:11.607 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:54:11.608 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:54:19.700 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1300, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:54:34.572 | INFO     | torch._tensor:to:88 - Fault Injected To: (1350, 2)
2023-11-20 17:54:45.550 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:54:45.551 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:54:53.617 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1350, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:55:08.190 | INFO     | torch._tensor:to:88 - Fault Injected To: (1400, 2)
2023-11-20 17:55:19.070 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:55:19.071 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:55:27.085 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1400, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:55:42.078 | INFO     | torch._tensor:to:88 - Fault Injected To: (1450, 2)
2023-11-20 17:55:53.019 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:55:53.020 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:56:00.986 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1450, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:56:15.550 | INFO     | torch._tensor:to:88 - Fault Injected To: (1500, 2)
2023-11-20 17:56:26.445 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:56:26.447 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:56:34.406 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1500, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:56:48.902 | INFO     | torch._tensor:to:88 - Fault Injected To: (1550, 2)
2023-11-20 17:56:59.708 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:56:59.709 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:57:07.750 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1550, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:57:22.432 | INFO     | torch._tensor:to:88 - Fault Injected To: (1600, 2)
2023-11-20 17:57:33.205 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:57:33.206 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:57:41.316 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1600, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:57:55.703 | INFO     | torch._tensor:to:88 - Fault Injected To: (1650, 2)
2023-11-20 17:58:06.724 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:58:06.725 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:58:14.677 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1650, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:58:29.342 | INFO     | torch._tensor:to:88 - Fault Injected To: (1700, 2)
2023-11-20 17:58:40.132 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:58:40.133 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:58:48.096 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1700, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:59:03.021 | INFO     | torch._tensor:to:88 - Fault Injected To: (1750, 2)
2023-11-20 17:59:13.856 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:59:13.857 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:59:21.884 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1750, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 17:59:36.068 | INFO     | torch._tensor:to:88 - Fault Injected To: (1800, 2)
2023-11-20 17:59:46.946 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 17:59:46.947 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 17:59:54.888 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1800, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:00:09.583 | INFO     | torch._tensor:to:88 - Fault Injected To: (1850, 2)
2023-11-20 18:00:20.500 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:00:20.501 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:00:28.487 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1850, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:00:43.197 | INFO     | torch._tensor:to:88 - Fault Injected To: (1900, 2)
2023-11-20 18:00:53.985 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:00:53.986 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:01:02.150 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1900, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:01:16.843 | INFO     | torch._tensor:to:88 - Fault Injected To: (1950, 2)
2023-11-20 18:01:27.746 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:01:27.747 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:01:35.699 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (1950, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:01:50.436 | INFO     | torch._tensor:to:88 - Fault Injected To: (2000, 2)
2023-11-20 18:02:01.238 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:02:01.239 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:02:09.236 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2000, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:02:24.230 | INFO     | torch._tensor:to:88 - Fault Injected To: (2050, 2)
2023-11-20 18:02:35.095 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:02:35.097 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:02:43.101 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2050, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:02:58.210 | INFO     | torch._tensor:to:88 - Fault Injected To: (2100, 2)
2023-11-20 18:03:09.133 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:03:09.134 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:03:17.508 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2100, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:03:32.206 | INFO     | torch._tensor:to:88 - Fault Injected To: (2150, 2)
2023-11-20 18:03:43.258 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:03:43.259 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:03:51.092 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2150, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:04:06.440 | INFO     | torch._tensor:to:88 - Fault Injected To: (2200, 2)
2023-11-20 18:04:17.557 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:04:17.558 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:04:25.604 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2200, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:04:40.346 | INFO     | torch._tensor:to:88 - Fault Injected To: (2250, 2)
2023-11-20 18:04:51.181 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:04:51.182 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:04:59.277 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2250, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:05:14.868 | INFO     | torch._tensor:to:88 - Fault Injected To: (2300, 2)
2023-11-20 18:05:25.760 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:05:25.761 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:05:34.016 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2300, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:05:49.513 | INFO     | torch._tensor:to:88 - Fault Injected To: (2350, 2)
2023-11-20 18:06:00.396 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:06:00.397 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:06:08.813 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2350, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:06:23.851 | INFO     | torch._tensor:to:88 - Fault Injected To: (2400, 2)
2023-11-20 18:06:34.744 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:06:34.745 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:06:42.715 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2400, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:06:57.606 | INFO     | torch._tensor:to:88 - Fault Injected To: (2450, 2)
2023-11-20 18:07:08.562 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:07:08.563 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:07:16.546 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2450, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:07:31.516 | INFO     | torch._tensor:to:88 - Fault Injected To: (2500, 2)
2023-11-20 18:07:42.510 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:07:42.511 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:07:50.396 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2500, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:08:05.546 | INFO     | torch._tensor:to:88 - Fault Injected To: (2550, 2)
2023-11-20 18:08:16.402 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:08:16.403 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:08:24.405 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2550, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:08:39.075 | INFO     | torch._tensor:to:88 - Fault Injected To: (2600, 2)
2023-11-20 18:08:50.087 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:08:50.087 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:08:58.038 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2600, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:09:12.823 | INFO     | torch._tensor:to:88 - Fault Injected To: (2650, 2)
2023-11-20 18:09:23.675 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:09:23.676 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:09:31.782 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2650, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:09:47.591 | INFO     | torch._tensor:to:88 - Fault Injected To: (2700, 2)
2023-11-20 18:09:58.449 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:09:58.450 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:10:06.568 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2700, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:10:21.539 | INFO     | torch._tensor:to:88 - Fault Injected To: (2750, 2)
2023-11-20 18:10:32.420 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:10:32.422 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:10:40.359 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2750, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:10:55.162 | INFO     | torch._tensor:to:88 - Fault Injected To: (2800, 2)
2023-11-20 18:11:06.047 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:11:06.048 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:11:13.967 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2800, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:11:28.957 | INFO     | torch._tensor:to:88 - Fault Injected To: (2850, 2)
2023-11-20 18:11:39.811 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:11:39.812 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:11:48.028 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2850, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:12:02.825 | INFO     | torch._tensor:to:88 - Fault Injected To: (2900, 2)
2023-11-20 18:12:13.692 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:12:13.693 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:12:21.731 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2900, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:12:36.960 | INFO     | torch._tensor:to:88 - Fault Injected To: (2950, 2)
2023-11-20 18:12:47.709 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:12:47.711 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:12:55.739 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (2950, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:13:10.758 | INFO     | torch._tensor:to:88 - Fault Injected To: (3000, 2)
2023-11-20 18:13:21.695 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:13:21.696 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:13:29.724 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3000, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:13:44.661 | INFO     | torch._tensor:to:88 - Fault Injected To: (3050, 2)
2023-11-20 18:13:55.619 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:13:55.620 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:14:03.554 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3050, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:14:18.672 | INFO     | torch._tensor:to:88 - Fault Injected To: (3100, 2)
2023-11-20 18:14:29.478 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:14:29.479 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:14:37.562 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3100, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:14:52.806 | INFO     | torch._tensor:to:88 - Fault Injected To: (3150, 2)
2023-11-20 18:15:03.640 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:15:03.640 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:15:11.651 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3150, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:15:26.751 | INFO     | torch._tensor:to:88 - Fault Injected To: (3200, 2)
2023-11-20 18:15:37.637 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:15:37.638 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:15:45.568 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3200, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:16:00.762 | INFO     | torch._tensor:to:88 - Fault Injected To: (3250, 2)
2023-11-20 18:16:11.743 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:16:11.744 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:16:19.803 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3250, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:16:35.253 | INFO     | torch._tensor:to:88 - Fault Injected To: (3300, 2)
2023-11-20 18:16:46.211 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:16:46.212 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:16:54.109 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3300, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:17:09.240 | INFO     | torch._tensor:to:88 - Fault Injected To: (3350, 2)
2023-11-20 18:17:20.041 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:17:20.042 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:17:28.130 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3350, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:17:43.301 | INFO     | torch._tensor:to:88 - Fault Injected To: (3400, 2)
2023-11-20 18:17:54.164 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:17:54.165 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:18:02.136 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3400, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:18:17.130 | INFO     | torch._tensor:to:88 - Fault Injected To: (3450, 2)
2023-11-20 18:18:28.005 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:18:28.006 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:18:35.993 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3450, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:18:51.222 | INFO     | torch._tensor:to:88 - Fault Injected To: (3500, 2)
2023-11-20 18:19:02.128 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:19:02.129 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:19:10.235 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3500, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:19:25.296 | INFO     | torch._tensor:to:88 - Fault Injected To: (3550, 2)
2023-11-20 18:19:36.343 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:19:36.344 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:19:44.147 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3550, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:19:59.330 | INFO     | torch._tensor:to:88 - Fault Injected To: (3600, 2)
2023-11-20 18:20:10.157 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:20:10.158 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:20:18.200 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3600, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:20:33.895 | INFO     | torch._tensor:to:88 - Fault Injected To: (3650, 2)
2023-11-20 18:20:44.784 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:20:44.785 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:20:52.701 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3650, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:21:07.782 | INFO     | torch._tensor:to:88 - Fault Injected To: (3700, 2)
2023-11-20 18:21:18.509 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:21:18.510 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:21:26.549 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3700, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:21:41.884 | INFO     | torch._tensor:to:88 - Fault Injected To: (3750, 2)
2023-11-20 18:21:52.719 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:21:52.720 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:22:01.060 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3750, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:22:16.462 | INFO     | torch._tensor:to:88 - Fault Injected To: (3800, 2)
2023-11-20 18:22:26.285 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:22:26.286 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:22:34.236 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3800, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:22:49.453 | INFO     | torch._tensor:to:88 - Fault Injected To: (3850, 2)
2023-11-20 18:23:00.330 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:23:00.331 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:23:08.248 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3850, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:23:23.807 | INFO     | torch._tensor:to:88 - Fault Injected To: (3900, 2)
2023-11-20 18:23:34.771 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:23:34.772 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:23:42.673 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3900, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:23:58.206 | INFO     | torch._tensor:to:88 - Fault Injected To: (3950, 2)
2023-11-20 18:24:09.076 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:24:09.077 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:24:17.171 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (3950, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:24:32.487 | INFO     | torch._tensor:to:88 - Fault Injected To: (4000, 2)
2023-11-20 18:24:43.320 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:24:43.320 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:24:51.404 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4000, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:25:06.872 | INFO     | torch._tensor:to:88 - Fault Injected To: (4050, 2)
2023-11-20 18:25:17.688 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:25:17.689 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:25:25.705 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4050, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:25:40.981 | INFO     | torch._tensor:to:88 - Fault Injected To: (4100, 2)
2023-11-20 18:25:50.849 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:25:50.850 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:25:58.992 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4100, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:26:14.218 | INFO     | torch._tensor:to:88 - Fault Injected To: (4150, 2)
2023-11-20 18:26:24.063 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:26:24.065 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:26:31.988 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4150, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:26:47.358 | INFO     | torch._tensor:to:88 - Fault Injected To: (4200, 2)
2023-11-20 18:26:58.216 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:26:58.217 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:27:06.427 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4200, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:27:21.670 | INFO     | torch._tensor:to:88 - Fault Injected To: (4250, 2)
2023-11-20 18:27:31.590 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:27:31.591 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:27:39.737 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4250, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:27:55.199 | INFO     | torch._tensor:to:88 - Fault Injected To: (4300, 2)
2023-11-20 18:28:06.143 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:28:06.145 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:28:14.108 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4300, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:28:29.358 | INFO     | torch._tensor:to:88 - Fault Injected To: (4350, 2)
2023-11-20 18:28:40.163 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:28:40.164 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:28:48.159 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4350, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:29:03.512 | INFO     | torch._tensor:to:88 - Fault Injected To: (4400, 2)
2023-11-20 18:29:14.257 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:29:14.258 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:29:22.314 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4400, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:29:37.583 | INFO     | torch._tensor:to:88 - Fault Injected To: (4450, 2)
2023-11-20 18:29:48.623 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:29:48.624 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:29:56.554 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4450, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:30:12.046 | INFO     | torch._tensor:to:88 - Fault Injected To: (4500, 2)
2023-11-20 18:30:23.118 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:30:23.120 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:30:31.016 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4500, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:30:46.081 | INFO     | torch._tensor:to:88 - Fault Injected To: (4550, 2)
2023-11-20 18:30:56.953 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:30:56.954 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:31:04.985 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4550, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:31:20.178 | INFO     | torch._tensor:to:88 - Fault Injected To: (4600, 2)
2023-11-20 18:31:30.975 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:31:30.976 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:31:39.144 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4600, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:31:54.372 | INFO     | torch._tensor:to:88 - Fault Injected To: (4650, 2)
2023-11-20 18:32:05.182 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:32:05.183 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:32:13.149 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4650, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:32:28.560 | INFO     | torch._tensor:to:88 - Fault Injected To: (4700, 2)
2023-11-20 18:32:39.330 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:32:39.331 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:32:47.193 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4700, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:33:02.436 | INFO     | torch._tensor:to:88 - Fault Injected To: (4750, 2)
2023-11-20 18:33:13.250 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:33:13.251 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:33:21.488 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4750, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:33:36.740 | INFO     | torch._tensor:to:88 - Fault Injected To: (4800, 2)
2023-11-20 18:33:47.740 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:33:47.741 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:33:55.687 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4800, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:34:10.726 | INFO     | torch._tensor:to:88 - Fault Injected To: (4850, 2)
2023-11-20 18:34:21.666 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:34:21.668 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:34:29.677 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4850, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:34:44.929 | INFO     | torch._tensor:to:88 - Fault Injected To: (4900, 2)
2023-11-20 18:34:55.846 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:34:55.847 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:35:03.890 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4900, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:35:19.033 | INFO     | torch._tensor:to:88 - Fault Injected To: (4950, 2)
2023-11-20 18:35:29.776 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:35:29.777 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:35:37.762 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (4950, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:35:53.137 | INFO     | torch._tensor:to:88 - Fault Injected To: (5000, 2)
2023-11-20 18:36:03.932 | ERROR    | __mp_main__:main_worker:237 - Failed to restore checkpoint: PytorchStreamReader failed reading zip archive: failed finding central directory
2023-11-20 18:36:03.933 | INFO     | __mp_main__:main_worker:238 - Give up CheckFreq Resume and Simulate Restart From Default Checkpoint (We Skip the Proper Process to Save Time, Please use the default checkpoint result as reference here)
2023-11-20 18:36:11.885 | INFO     | torch:fault_injection_scheduler_and_recorder:999 - (5000, 2) Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:37:28.035 | INFO     | torch:fault_injection_scheduler_and_recorder_for_epoch:1035 - 2 Fault Not Properly Recovered, Please Use the Default Checkpoint Recovery Time for this Injection
2023-11-20 18:37:29.347 | INFO     | daifu:log_program_end:40 - Program End with Quality Measure 0.11
